{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyMSVsy9DHVLJpYDDnLbOhF+"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":45,"metadata":{"id":"0NhTatqEG3YM","executionInfo":{"status":"ok","timestamp":1748451324958,"user_tz":-330,"elapsed":4,"user":{"displayName":"SHYAM SUNDAR YADAV","userId":"11177267661583525331"}}},"outputs":[],"source":["import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","from sklearn.model_selection import train_test_split\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.metrics import accuracy_score\n","import warnings\n","from sklearn.datasets import load_diabetes\n","warnings.filterwarnings('ignore')\n"]},{"cell_type":"markdown","source":["we'll implement linear regression from scratch using gradient descent. Starting with dataset loading, we'll cover the mathematical foundations and step-by-step code implementation.\n","\n","The goal is to understand how linear regression works, how gradient descent optimizes model parameters, and how to build it without high-level machine learning libraries.\n","\n","Table of Contents\n","Importing Libraries\n","Setting up the necessary libraries for data manipulation, model implementation, and visualization.\n","\n","Loading and Exploring the Dataset\n","Understanding the structure of the dataset and initial data exploration.\n","\n","Preparing the Data\n","Preprocessing the data by scaling features and splitting into training and testing sets.\n","\n","Initializing Parameters\n","Defining the initial parameters for the model, including weights and bias.\n","\n","Defining the Prediction Function\n","Implementing the model's prediction function to make estimates based on input data.\n","\n","Defining the Cost Function\n","Formulating the cost function to measure the accuracy of predictions against actual values.\n","\n","Computing the Gradients\n","Calculating the gradients for weights and bias to optimize the cost function.\n","\n","Updating Parameters Using Gradient Descent\n","Applying gradient descent to adjust parameters and minimize the cost function.\n","\n","Training the Model\n","Training the model using the data and updating parameters through iterative optimization.\n","\n","Evaluating Model Performance with Test Data\n","Assessing the model's performance using test data and relevant metrics.\n","\n","Conclusion\n","Summarizing the key findings and insights from the model implementation.\n","\n","Comparison with Sklearn Linear Regression\n","Side by side comparison of the algorithm that we've written with the algorithms predefined in sklearn to check performance\n","\n","1. Importing Libraries\n","The following code imports essential libraries for linear regression and dataset loading:\n","\n","numpy: For numerical computing and array manipulation.\n","load_diabetes: Loads the Diabetes dataset for regression tasks.\n","matplotlib.pyplot: For visualizations such as loss curves and predictions."],"metadata":{"id":"zjQm4SFUyYqd"}},{"cell_type":"code","source":["data = load_diabetes()\n"],"metadata":{"id":"L-qXZoPFISPM","executionInfo":{"status":"ok","timestamp":1748451324963,"user_tz":-330,"elapsed":2,"user":{"displayName":"SHYAM SUNDAR YADAV","userId":"11177267661583525331"}}},"execution_count":46,"outputs":[]},{"cell_type":"code","source":["x = data.data\n","y = data.target\n","\n","print(\"Features names: \",data.feature_names)\n","print(\"Target names: \",data.target)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"O1B8EXKBIvp-","executionInfo":{"status":"ok","timestamp":1748451324971,"user_tz":-330,"elapsed":6,"user":{"displayName":"SHYAM SUNDAR YADAV","userId":"11177267661583525331"}},"outputId":"84c9aa8a-ef46-43e4-8f5d-3ef9a9378be8"},"execution_count":47,"outputs":[{"output_type":"stream","name":"stdout","text":["Features names:  ['age', 'sex', 'bmi', 'bp', 's1', 's2', 's3', 's4', 's5', 's6']\n","Target names:  [151.  75. 141. 206. 135.  97. 138.  63. 110. 310. 101.  69. 179. 185.\n"," 118. 171. 166. 144.  97. 168.  68.  49.  68. 245. 184. 202. 137.  85.\n"," 131. 283. 129.  59. 341.  87.  65. 102. 265. 276. 252.  90. 100.  55.\n","  61.  92. 259.  53. 190. 142.  75. 142. 155. 225.  59. 104. 182. 128.\n","  52.  37. 170. 170.  61. 144.  52. 128.  71. 163. 150.  97. 160. 178.\n","  48. 270. 202. 111.  85.  42. 170. 200. 252. 113. 143.  51.  52. 210.\n","  65. 141.  55. 134.  42. 111.  98. 164.  48.  96.  90. 162. 150. 279.\n","  92.  83. 128. 102. 302. 198.  95.  53. 134. 144. 232.  81. 104.  59.\n"," 246. 297. 258. 229. 275. 281. 179. 200. 200. 173. 180.  84. 121. 161.\n","  99. 109. 115. 268. 274. 158. 107.  83. 103. 272.  85. 280. 336. 281.\n"," 118. 317. 235.  60. 174. 259. 178. 128.  96. 126. 288.  88. 292.  71.\n"," 197. 186.  25.  84.  96. 195.  53. 217. 172. 131. 214.  59.  70. 220.\n"," 268. 152.  47.  74. 295. 101. 151. 127. 237. 225.  81. 151. 107.  64.\n"," 138. 185. 265. 101. 137. 143. 141.  79. 292. 178.  91. 116.  86. 122.\n","  72. 129. 142.  90. 158.  39. 196. 222. 277.  99. 196. 202. 155.  77.\n"," 191.  70.  73.  49.  65. 263. 248. 296. 214. 185.  78.  93. 252. 150.\n","  77. 208.  77. 108. 160.  53. 220. 154. 259.  90. 246. 124.  67.  72.\n"," 257. 262. 275. 177.  71.  47. 187. 125.  78.  51. 258. 215. 303. 243.\n","  91. 150. 310. 153. 346.  63.  89.  50.  39. 103. 308. 116. 145.  74.\n","  45. 115. 264.  87. 202. 127. 182. 241.  66.  94. 283.  64. 102. 200.\n"," 265.  94. 230. 181. 156. 233.  60. 219.  80.  68. 332. 248.  84. 200.\n","  55.  85.  89.  31. 129.  83. 275.  65. 198. 236. 253. 124.  44. 172.\n"," 114. 142. 109. 180. 144. 163. 147.  97. 220. 190. 109. 191. 122. 230.\n"," 242. 248. 249. 192. 131. 237.  78. 135. 244. 199. 270. 164.  72.  96.\n"," 306.  91. 214.  95. 216. 263. 178. 113. 200. 139. 139.  88. 148.  88.\n"," 243.  71.  77. 109. 272.  60.  54. 221.  90. 311. 281. 182. 321.  58.\n"," 262. 206. 233. 242. 123. 167.  63. 197.  71. 168. 140. 217. 121. 235.\n"," 245.  40.  52. 104. 132.  88.  69. 219.  72. 201. 110.  51. 277.  63.\n"," 118.  69. 273. 258.  43. 198. 242. 232. 175.  93. 168. 275. 293. 281.\n","  72. 140. 189. 181. 209. 136. 261. 113. 131. 174. 257.  55.  84.  42.\n"," 146. 212. 233.  91. 111. 152. 120.  67. 310.  94. 183.  66. 173.  72.\n","  49.  64.  48. 178. 104. 132. 220.  57.]\n"]}]},{"cell_type":"code","source":["data.keys()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"h6Gbp4dMJ44K","executionInfo":{"status":"ok","timestamp":1748451324977,"user_tz":-330,"elapsed":5,"user":{"displayName":"SHYAM SUNDAR YADAV","userId":"11177267661583525331"}},"outputId":"54ce25c7-a224-4cac-9516-865755e0fdfe"},"execution_count":48,"outputs":[{"output_type":"execute_result","data":{"text/plain":["dict_keys(['data', 'target', 'frame', 'DESCR', 'feature_names', 'data_filename', 'target_filename', 'data_module'])"]},"metadata":{},"execution_count":48}]},{"cell_type":"code","source":["print(data['DESCR'])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"BEyMwG8vJ9GG","executionInfo":{"status":"ok","timestamp":1748451324983,"user_tz":-330,"elapsed":5,"user":{"displayName":"SHYAM SUNDAR YADAV","userId":"11177267661583525331"}},"outputId":"eb26ff32-b1ca-4332-c95e-ee3632a3a9a2"},"execution_count":49,"outputs":[{"output_type":"stream","name":"stdout","text":[".. _diabetes_dataset:\n","\n","Diabetes dataset\n","----------------\n","\n","Ten baseline variables, age, sex, body mass index, average blood\n","pressure, and six blood serum measurements were obtained for each of n =\n","442 diabetes patients, as well as the response of interest, a\n","quantitative measure of disease progression one year after baseline.\n","\n","**Data Set Characteristics:**\n","\n",":Number of Instances: 442\n","\n",":Number of Attributes: First 10 columns are numeric predictive values\n","\n",":Target: Column 11 is a quantitative measure of disease progression one year after baseline\n","\n",":Attribute Information:\n","    - age     age in years\n","    - sex\n","    - bmi     body mass index\n","    - bp      average blood pressure\n","    - s1      tc, total serum cholesterol\n","    - s2      ldl, low-density lipoproteins\n","    - s3      hdl, high-density lipoproteins\n","    - s4      tch, total cholesterol / HDL\n","    - s5      ltg, possibly log of serum triglycerides level\n","    - s6      glu, blood sugar level\n","\n","Note: Each of these 10 feature variables have been mean centered and scaled by the standard deviation times the square root of `n_samples` (i.e. the sum of squares of each column totals 1).\n","\n","Source URL:\n","https://www4.stat.ncsu.edu/~boos/var.select/diabetes.html\n","\n","For more information see:\n","Bradley Efron, Trevor Hastie, Iain Johnstone and Robert Tibshirani (2004) \"Least Angle Regression,\" Annals of Statistics (with discussion), 407-499.\n","(https://web.stanford.edu/~hastie/Papers/LARS/LeastAngle_2002.pdf)\n","\n"]}]},{"cell_type":"code","source":["from sklearn.preprocessing import StandardScaler\n","feature_scaler = StandardScaler()\n","target_scaler = StandardScaler()\n","# x = feature_scaler.fit_transform(x)\n","# y = target_scaler.fit_transform(y.reshape(-1,1))\n","X,x_test,y,y_test = train_test_split(x,y,test_size=0.2,random_state=42)"],"metadata":{"id":"GPw-PqYlKHGq","executionInfo":{"status":"ok","timestamp":1748451324985,"user_tz":-330,"elapsed":1,"user":{"displayName":"SHYAM SUNDAR YADAV","userId":"11177267661583525331"}}},"execution_count":50,"outputs":[]},{"cell_type":"markdown","source":[],"metadata":{"id":"DDi2dOdiOerO"}},{"cell_type":"code","source":["X.shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"txG7ITn4OmEk","executionInfo":{"status":"ok","timestamp":1748451325026,"user_tz":-330,"elapsed":41,"user":{"displayName":"SHYAM SUNDAR YADAV","userId":"11177267661583525331"}},"outputId":"02528deb-405d-4365-eafd-b66364ae63c8"},"execution_count":51,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(353, 10)"]},"metadata":{},"execution_count":51}]},{"cell_type":"code","source":["x_test.shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"U-fcrKTxOpfu","executionInfo":{"status":"ok","timestamp":1748451325037,"user_tz":-330,"elapsed":12,"user":{"displayName":"SHYAM SUNDAR YADAV","userId":"11177267661583525331"}},"outputId":"d84756f2-2680-4c61-e67e-bceecc39ad6b"},"execution_count":52,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(89, 10)"]},"metadata":{},"execution_count":52}]},{"cell_type":"code","source":["m,n = X.shape  # 353, n = 10\n","w = np.zeros(n) # weight vector (shape: [10,])\n","b = 0 # Bias term (scaler)"],"metadata":{"id":"gpDbZvZcOz27","executionInfo":{"status":"ok","timestamp":1748451325038,"user_tz":-330,"elapsed":6,"user":{"displayName":"SHYAM SUNDAR YADAV","userId":"11177267661583525331"}}},"execution_count":53,"outputs":[]},{"cell_type":"markdown","source":["**Defining the prediction function**\n"],"metadata":{"id":"cEqW46cqPxHo"}},{"cell_type":"code","source":["def predict(X,w,b):\n","  return np.dot(X,w) + b"],"metadata":{"id":"hk0XtG-rPwuH","executionInfo":{"status":"ok","timestamp":1748451325038,"user_tz":-330,"elapsed":5,"user":{"displayName":"SHYAM SUNDAR YADAV","userId":"11177267661583525331"}}},"execution_count":54,"outputs":[]},{"cell_type":"markdown","source":["**Defining the cost function**"],"metadata":{"id":"47WB45W1QPj8"}},{"cell_type":"code","source":["def compute_cost(X,y,w,b):\n","  m = len(y)\n","  y_pred = predict(X,w,b)\n","  cost = (1/(2*m))*np.sum((y_pred-y)**2)\n","  return cost"],"metadata":{"id":"KfN6YC9hQVXv","executionInfo":{"status":"ok","timestamp":1748451325039,"user_tz":-330,"elapsed":5,"user":{"displayName":"SHYAM SUNDAR YADAV","userId":"11177267661583525331"}}},"execution_count":55,"outputs":[]},{"cell_type":"markdown","source":["**Computing the Gradients**"],"metadata":{"id":"0K7AZSdzQzAt"}},{"cell_type":"code","source":["def compute_gradients(X,y,w,b):\n","  m = len(y)\n","  y_pred = predict(X,w,b)\n","  error = y_pred - y\n","  dw = (1/2)*np.dot(X.T,error)\n","  db = (1/m)*np.sum(error)\n","  return dw,db"],"metadata":{"id":"o4UQYq3lQ6JJ","executionInfo":{"status":"ok","timestamp":1748451325039,"user_tz":-330,"elapsed":4,"user":{"displayName":"SHYAM SUNDAR YADAV","userId":"11177267661583525331"}}},"execution_count":56,"outputs":[]},{"cell_type":"markdown","source":["**Updating the parameters Using Gradient Descent**"],"metadata":{"id":"gimg8RPxRx3-"}},{"cell_type":"code","source":["def update_updates(w,b,dw,db,learning_rate):\n","  w = w - learning_rate*dw\n","  b = b - learning_rate*db\n","  return w,b\n"],"metadata":{"id":"E-EukZooSSfA","executionInfo":{"status":"ok","timestamp":1748451325039,"user_tz":-330,"elapsed":3,"user":{"displayName":"SHYAM SUNDAR YADAV","userId":"11177267661583525331"}}},"execution_count":57,"outputs":[]},{"cell_type":"markdown","source":["# This code performs the training of the linear regression model using gradient descent. It iteratively updates the model's parameters (weights and bias) and tracks the cost function:\n","\n","# learning_rate: The step size for updating the parameters during each iteration. Set to 0.01.\n","# num_iterations: The number of iterations for the gradient descent process. Set to 1000.\n","# cost_history: A list that stores the cost value at each iteration to track the convergence of the model.\n","The training loop performs the following steps for each iteration:\n","\n","# Prediction: Uses the predict function to compute the predicted target values (y_pred).\n","# Cost Calculation: Computes the cost (error) using the compute_cost function.\n","# Store Cost: Appends the cost to the cost_history list for tracking.\n","# Gradient Calculation: Computes the gradients for the weights and bias using compute_gradients.\n","# Parameter Update: Updates the weights and bias using the update_parameters function with the calculated gradients and learning rate.\n","# Iteration Logging: Every 100th iteration, prints the current iteration number and the corresponding cost."],"metadata":{"id":"_uWSMGd8zGBA"}},{"cell_type":"markdown","source":["**Training the model**"],"metadata":{"id":"ihx5rH9NSm6t"}},{"cell_type":"code","source":["w = np.zeros(n)\n","b= 0\n","\n","learning_rate = .001\n","num_iterations = 10000\n","cost_history = []\n","\n","parameters = {}\n","\n","for i in range(num_iterations):\n","  y_pred = predict(X,w,b)\n","  cost = compute_cost(X,y,w,b)\n","  dw,db = compute_gradients(X,y,w,b)\n","  w,b = update_updates(w,b,dw,db,learning_rate)\n","\n","  if i % 1000 == 0:\n","    cost_history.append(cost)\n","    print(f'Iteration {i}: Cost = {cost:.4f}')\n","\n","    parameters = {'weights': w.tolist(),'bias': b}\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"eCE18u55bTcq","executionInfo":{"status":"ok","timestamp":1748451325289,"user_tz":-330,"elapsed":252,"user":{"displayName":"SHYAM SUNDAR YADAV","userId":"11177267661583525331"}},"outputId":"01fa2831-067c-46de-8e6d-4cd9a8ca78ef"},"execution_count":58,"outputs":[{"output_type":"stream","name":"stdout","text":["Iteration 0: Cost = 14855.6615\n","Iteration 1000: Cost = 3271.1328\n","Iteration 2000: Cost = 1757.3349\n","Iteration 3000: Cost = 1523.6064\n","Iteration 4000: Cost = 1475.9455\n","Iteration 5000: Cost = 1461.5489\n","Iteration 6000: Cost = 1455.5574\n","Iteration 7000: Cost = 1452.6001\n","Iteration 8000: Cost = 1451.0035\n","Iteration 9000: Cost = 1450.0832\n"]}]},{"cell_type":"code","source":["parameters"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"D6-rZeD4dTfH","executionInfo":{"status":"ok","timestamp":1748451325295,"user_tz":-330,"elapsed":5,"user":{"displayName":"SHYAM SUNDAR YADAV","userId":"11177267661583525331"}},"outputId":"f48f50ba-6111-43ae-f641-77aed949b214"},"execution_count":59,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'weights': [41.605847988944575,\n","  -231.3991645351087,\n","  543.679891573393,\n","  335.5767831793388,\n","  -89.87164856959676,\n","  -129.99323505686326,\n","  -218.62796623956459,\n","  145.38495856264245,\n","  401.8013505763632,\n","  85.38120439585823],\n"," 'bias': np.float64(151.29409390672157)}"]},"metadata":{},"execution_count":59}]},{"cell_type":"code","source":["import json\n","with open('parameters.json', 'w') as f:\n","  json.dump(parameters, f)"],"metadata":{"id":"kJdGzGwWdgFM","executionInfo":{"status":"ok","timestamp":1748451325306,"user_tz":-330,"elapsed":8,"user":{"displayName":"SHYAM SUNDAR YADAV","userId":"11177267661583525331"}}},"execution_count":60,"outputs":[]},{"cell_type":"code","source":["for i in range(10):\n","  print(int(y_test[i]), int(np.dot(x_test[i],parameters['weights'])+parameters['bias']))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"G5MZ4LuieN3g","executionInfo":{"status":"ok","timestamp":1748451325340,"user_tz":-330,"elapsed":33,"user":{"displayName":"SHYAM SUNDAR YADAV","userId":"11177267661583525331"}},"outputId":"5408d0c3-1547-4424-f2f0-702a4ed9f709"},"execution_count":61,"outputs":[{"output_type":"stream","name":"stdout","text":["219 140\n","70 180\n","202 140\n","230 292\n","111 121\n","84 94\n","242 255\n","272 189\n","94 84\n","96 112\n"]}]},{"cell_type":"markdown","source":["**Evaluating the model peformance with test data**"],"metadata":{"id":"8k9CjAm4f4Ph"}},{"cell_type":"code","source":["y_pred = predict(X,w,b)\n","final_cost = compute_cost(X,y,w,b)\n","mse = 2 * final_cost\n","\n","\n","print(f'Final Cost: {final_cost:.4f}')\n","print(f'Mean Squared Error: {mse:.4f}')\n","\n","print('Final Weights:',w)\n","print('Final Bias:',b)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1m-AnGy9h_os","executionInfo":{"status":"ok","timestamp":1748451325357,"user_tz":-330,"elapsed":15,"user":{"displayName":"SHYAM SUNDAR YADAV","userId":"11177267661583525331"}},"outputId":"1eda82e8-722b-4066-de84-417fe7a932d2"},"execution_count":62,"outputs":[{"output_type":"stream","name":"stdout","text":["Final Cost: 1449.5180\n","Mean Squared Error: 2899.0360\n","Final Weights: [  41.20118615 -234.44868198  547.59303735  337.32489304  -93.3354987\n"," -129.32353238 -217.87242467  146.52225533  406.15336339   79.22448324]\n","Final Bias: 151.2993378503322\n"]}]},{"cell_type":"code","source":["y_pred_test = predict(x_test, w, b)\n","\n","# Calculate metrics\n","\n","print(f\"Residual Analysis : {(np.abs(y_test - y_pred_test)).mean()}\")\n","\n","mae = np.abs(y_test - y_pred_test).mean()\n","mse = ((y_test - y_pred_test)**2).mean()\n","rmse = np.sqrt(((y_test - y_pred_test)**2).sum()/len(y_test))\n","\n","\n","print(f\"Mean Absolute Error (MAE): {mae:.4f}\")\n","print(f\"Mean Squared Error (MSE): {mse:.4f}\")\n","print(f\"Root Mean Squared Error (RMSE): {rmse:.4f}\")\n","\n","\n","SS_res = np.sum((y_test - y_pred_test)**2)        # Sum of squares of residuals(diff bet actual and predicted values)\n","SS_tot = np.sum((y_test - np.mean(y_test))**2)    # Total sum of squares\n","\n","r2_ = 1 - (SS_res / SS_tot)\n","\n","print(f\"R-squared: {r2_:.4f}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"kGBmy-T0zgZ9","executionInfo":{"status":"ok","timestamp":1748451325370,"user_tz":-330,"elapsed":12,"user":{"displayName":"SHYAM SUNDAR YADAV","userId":"11177267661583525331"}},"outputId":"e94e7101-a337-43ea-b499-6db70e8880d5"},"execution_count":63,"outputs":[{"output_type":"stream","name":"stdout","text":["Residual Analysis : 42.9550425765526\n","Mean Absolute Error (MAE): 42.9550\n","Mean Squared Error (MSE): 2879.8412\n","Root Mean Squared Error (RMSE): 53.6642\n","R-squared: 0.4564\n"]}]},{"cell_type":"markdown","source":["**Comparison with Sklearn Linear Regression**"],"metadata":{"id":"Tp0j8WT70LMo"}},{"cell_type":"code","source":["from sklearn.linear_model import SGDRegressor\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import mean_squared_error, r2_score\n","\n","model = SGDRegressor(\n","    loss='squared_error',\n","    alpha=0.0,\n","    learning_rate='constant',  # Set to 'constant' for a fixed learning rate\n","    eta0=0.01,                 # Initial learning rate (will remain fixed)\n","    max_iter=1000,\n","    random_state=42\n","    # tol = None                    # no early stopping\n","  )\n","\n","\n","model.fit(X, y)  # Use training data for fitting\n","\n","# 4. Make predictions on the test set\n","y_pred_test = model.predict(x_test)\n","\n","# 5. Evaluate the model\n","mse = mean_squared_error(y_test, y_pred_test)\n","r2 = r2_score(y_test, y_pred_test)\n","\n","print(f\"Mean Squared Error: {mse:.4f}\")\n","print(f\"R-squared: {r2:.4f}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"MV3rXcOU0Kwc","executionInfo":{"status":"ok","timestamp":1748451325375,"user_tz":-330,"elapsed":4,"user":{"displayName":"SHYAM SUNDAR YADAV","userId":"11177267661583525331"}},"outputId":"52b3263f-b81b-461c-9676-a3172fbf1b36"},"execution_count":64,"outputs":[{"output_type":"stream","name":"stdout","text":["Mean Squared Error: 2957.7661\n","R-squared: 0.4417\n"]}]}]}